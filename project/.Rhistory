labels = c("A", "B", "C"))
# table or proportions with more informative labels
round(prop.table(table(wines$label)) * 100, digits = 1)
# create normalization function
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# normalize the wbcd data
wines_n <- as.data.frame(lapply(wines[2:14], normalize))
# add the label column
wines_n$label<-as.factor(wines[,1])
# set up trainning and test data sets
set.seed(3033)
indx <- sample(1:nrow(wines_n), as.integer(0.7*nrow(wines_n)))
#View(indx)
#indx
training <- wines_n[indx,1:13]
testing <- wines_n[-indx,1:13]
train_labels <- wines_n[indx,14]
test_labels <- wines_n[-indx,14]
trl<-wines_n[indx,]
tel<-wines_n[-indx,]
# check missing data
anyNA(training)
anyNA(testing)
# load the "class" library
library(class)
test_pred <- knn(train = training[1:13], test = testing[1:13],
cl = train_labels, k = 4)
head(testing)
head(test_pred)
# load the "gmodels" library
library(gmodels)
# Create the cross tabulation of predicted vs. actual
CrossTable(x = test_labels, y = test_pred,
prop.chisq = FALSE)
#we can see the error is not very high, only 2 mistake.
# use the scale() function to z-score standardize a data frame
wines_z <- as.data.frame(scale(wines[2:14]))
# add the label column
wines_z$label<-as.factor(wines[,1])
# set up trainning and test data sets
set.seed(3033)
indx <- sample(1:nrow(wines_z), as.integer(0.7*nrow(wines_z)))
#indx
training1 <- wines_z[indx,1:13]
testing1 <- wines_z[-indx,1:13]
train_labels1 <- wines_z[indx,14]
test_labels1 <- wines_z[-indx,14]
# check missing data
anyNA(training1)
anyNA(testing1)
#start time
strt<-Sys.time()
test_pred <- knn(train = training[1:13], test = testing[1:13], cl = train_labels, k = 1)
CrossTable(x = test_labels, y = test_pred,prop.chisq = FALSE)
test_pred <- knn(train = training[1:13], test = testing[1:13], cl = train_labels, k=4)
CrossTable(x = test_labels, y = test_pred, prop.chisq=FALSE)
test_pred <- knn(train = training[1:13], test = testing[1:13], cl = train_labels, k = 8)
CrossTable(x = test_labels, y = test_pred,prop.chisq = FALSE)
test_pred <- knn(train = training[1:13], test = testing[1:13], cl = train_labels, k=12)
CrossTable(x = test_labels, y = test_pred, prop.chisq=FALSE)
test_pred <- knn(train = training[1:13], test = testing[1:13], cl = train_labels, k = 14)
CrossTable(x = test_labels, y = test_pred,prop.chisq = FALSE)
test_pred <- knn(train = training[1:13], test = testing[1:13], cl = train_labels, k=20)
CrossTable(x = test_labels, y = test_pred, prop.chisq=FALSE)
#end time
print(Sys.time()-strt)
# we find the best is 1 mistake improve our model when k=12 and 14.
library(tidyr)
library(dplyr)
library(Rcpp)
library(ggplot2)
library(caret)
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(3333)
knn_fit <- train(label ~., data = trl, method = "knn",
trControl=trctrl,
preProcess = c("center", "scale"),
tuneLength = 10)
knn_fit
#k = 21, give the best accurarcy=0.97 and Kappa=0.95
# use the model to test the testing data
knnPredict <- predict(knn_fit,newdata = tel )
#Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(knnPredict, tel$label )
# only 3 B mistaked as A, not very high for the testing data. Also, the accurarcy is 0.9444 and the Kappa is 0.916
library(ranger)
library(randomForest)
library(caret)
library(randomForest)
set.seed(3033)
rf <- randomForest(label ~ ., data = trl)
rf
library(caret)
ctrl <- trainControl(method = "repeatedcv",
number = 10, repeats = 10)
# auto-tune a random forest
grid_rf <- expand.grid(.mtry = c(1,2,4,6))
set.seed(300)
m_rf <- train(label ~ ., data = trl, method = "rf",
metric = "Kappa", trControl = ctrl,
tuneGrid = grid_rf)
m_rf
#mtry = 1, Accurart is 0.9821404 and kappa is 0.9730934
rfPredict <- predict(m_rf,newdata = tel )
confusionMatrix(rfPredict, tel$label )
# we find that the accuray is 1 and kappa is 1, excellent.
source('~/R/6620/Chap05/MLwR_v2_05_update2.r')
## Example: Identifying Risky Bank Loans ----
## Step 1: Download the data ----
URL <- "http://www.sci.csueastbay.edu/~esuess/classes/Statistics_6620/Presentations/ml7/credit.csv"
download.file(URL, destfile = "credit.csv", method="libcurl")
## Step 2: Exploring and preparing the data ----
credit <- read.csv("credit.csv", stringsAsFactors = TRUE)
str(credit)
# look at two characteristics of the applicant
table(credit$checking_balance)
table(credit$savings_balance)
# look at two characteristics of the loan
summary(credit$months_loan_duration)
summary(credit$amount)
# look at the class variable
table(credit$default)
# create a random sample for training and test data
# use set.seed to use the same random number sequence as the tutorial
set.seed(123)
train_sample <- sample(1000, 900)
str(train_sample)
# split the data frames
credit_train <- credit[train_sample, ]
credit_test  <- credit[-train_sample, ]
# check the proportion of class variable
prop.table(table(credit_train$default))
prop.table(table(credit_test$default))
## Step 3: Training a model on the data ----
# build the simplest decision tree
#install.packages("C50")
#install.packages("libcoin")
library(libcoin)
library(C50)
credit_model <- C5.0(credit_train[-17], credit_train$default)
# display simple facts about the tree
credit_model
# display detailed information about the tree
summary(credit_model)
## Step 4: Evaluating model performance ----
# create a factor vector of predictions on test data
credit_pred <- predict(credit_model, credit_test)
# cross tabulation of predicted versus actual classes
library(gmodels)
CrossTable(credit_test$default, credit_pred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
## Step 5: Improving model performance ----
## Boosting the accuracy of decision trees
# boosted decision tree with 10 trials
credit_boost10 <- C5.0(credit_train[-17], credit_train$default,
trials = 10)
credit_boost10
summary(credit_boost10)
credit_boost_pred10 <- predict(credit_boost10, credit_test)
CrossTable(credit_test$default, credit_boost_pred10,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
##### Chapter 5: Classification using Decision Trees and Rules -------------------
#### Part 1: Decision Trees -------------------
## Understanding Decision Trees ----
# calculate entropy of a two-class segment
-0.60 * log2(0.60) - 0.40 * log2(0.40)
curve(-x * log2(x) - (1 - x) * log2(1 - x),
col = "red", xlab = "x", ylab = "Entropy", lwd = 4)
## Understanding Decision Trees ----
# calculate entropy of a two-class segment
-0.60 * log2(0.60) - 0.40 * log2(0.40)
curve(-x * log2(x) - (1 - x) * log2(1 - x),
col = "red", xlab = "x", ylab = "Entropy", lwd = 4)
# import the CSV file
wines<- read.csv("wines.csv")
names(wines) <- c("label",
"Alcohol",
"Malic_acid",
"Ash",
"Alcalinity_of_ash",
"Magnesium",
"Total_phenols",
"Flavanoids",
"Nonflavanoid_phenols",
"Proanthocyanins",
"Color_intensity",
"Hue",
"OD280_OD315_of_diluted_wines",
"Proline")
head(wines)
# examine the structure of the wbcd data frame
#str(wines)
library(ggplot2)
plt1 <- ggplot(wines, aes(x = Alcohol, y = Magnesium, colour = as.factor(label))) +
geom_point(size=3) +
ggtitle("Wines")
plt2 <- ggplot(wines, aes(x = Alcohol, y = Proline, colour = as.factor(label))) +
geom_point(size=3) +
ggtitle("Wines")
plt1
plt2
# table of labels
table(wines$label)
# recode label as a factor
wines$label <- factor(wines$label, levels = c("1","2","3"),
labels = c("A", "B", "C"))
# table or proportions with more informative labels
round(prop.table(table(wines$label)) * 100, digits = 1)
# create normalization function
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# normalize the wbcd data
wines_n <- as.data.frame(lapply(wines[2:14], normalize))
# add the label column
wines_n$label<-as.factor(wines[,1])
# set up trainning and test data sets
set.seed(3033)
indx <- sample(1:nrow(wines_n), as.integer(0.7*nrow(wines_n)))
#View(indx)
#indx
training <- wines_n[indx,1:13]
testing <- wines_n[-indx,1:13]
train_labels <- wines_n[indx,14]
test_labels <- wines_n[-indx,14]
trl<-wines_n[indx,]
tel<-wines_n[-indx,]
# check missing data
anyNA(training)
anyNA(testing)
# load the "class" library
library(class)
test_pred <- knn(train = training[1:13], test = testing[1:13],
cl = train_labels, k = 4)
head(testing)
head(test_pred)
# load the "gmodels" library
library(gmodels)
# Create the cross tabulation of predicted vs. actual
CrossTable(x = test_labels, y = test_pred,
prop.chisq = FALSE)
#we can see the error is not very high, only 2 mistake.
# use the scale() function to z-score standardize a data frame
wines_z <- as.data.frame(scale(wines[2:14]))
# add the label column
wines_z$label<-as.factor(wines[,1])
# set up trainning and test data sets
set.seed(3033)
indx <- sample(1:nrow(wines_z), as.integer(0.7*nrow(wines_z)))
#indx
training1 <- wines_z[indx,1:13]
testing1 <- wines_z[-indx,1:13]
train_labels1 <- wines_z[indx,14]
test_labels1 <- wines_z[-indx,14]
# check missing data
anyNA(training1)
anyNA(testing1)
#start time
strt<-Sys.time()
test_pred <- knn(train = training[1:13], test = testing[1:13], cl = train_labels, k = 1)
CrossTable(x = test_labels, y = test_pred,prop.chisq = FALSE)
test_pred <- knn(train = training[1:13], test = testing[1:13], cl = train_labels, k=4)
CrossTable(x = test_labels, y = test_pred, prop.chisq=FALSE)
test_pred <- knn(train = training[1:13], test = testing[1:13], cl = train_labels, k = 8)
CrossTable(x = test_labels, y = test_pred,prop.chisq = FALSE)
test_pred <- knn(train = training[1:13], test = testing[1:13], cl = train_labels, k=12)
CrossTable(x = test_labels, y = test_pred, prop.chisq=FALSE)
test_pred <- knn(train = training[1:13], test = testing[1:13], cl = train_labels, k = 14)
CrossTable(x = test_labels, y = test_pred,prop.chisq = FALSE)
test_pred <- knn(train = training[1:13], test = testing[1:13], cl = train_labels, k=20)
CrossTable(x = test_labels, y = test_pred, prop.chisq=FALSE)
#end time
print(Sys.time()-strt)
# we find the best is 1 mistake improve our model when k=12 and 14.
library(tidyr)
library(dplyr)
library(Rcpp)
library(ggplot2)
library(caret)
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(3333)
knn_fit <- train(label ~., data = trl, method = "knn",
trControl=trctrl,
preProcess = c("center", "scale"),
tuneLength = 10)
knn_fit
#k = 21, give the best accurarcy=0.97 and Kappa=0.95
# use the model to test the testing data
knnPredict <- predict(knn_fit,newdata = tel )
#Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(knnPredict, tel$label )
# only 3 B mistaked as A, not very high for the testing data. Also, the accurarcy is 0.9444 and the Kappa is 0.916
library(ranger)
library(randomForest)
library(caret)
library(randomForest)
set.seed(3033)
rf <- randomForest(label ~ ., data = trl)
rf
library(caret)
ctrl <- trainControl(method = "repeatedcv",
number = 10, repeats = 10)
# auto-tune a random forest
grid_rf <- expand.grid(.mtry = c(1,2,4,6))
set.seed(300)
m_rf <- train(label ~ ., data = trl, method = "rf",
metric = "Kappa", trControl = ctrl,
tuneGrid = grid_rf)
m_rf
#mtry = 1, Accurart is 0.9821404 and kappa is 0.9730934
rfPredict <- predict(m_rf,newdata = tel )
confusionMatrix(rfPredict, tel$label )
# we find that the accuray is 1 and kappa is 1, excellent.
library(broom)
library(tidyr)
library(caret)
library(tictoc)
library(lattice)
library(ggplot2)
library(ranger)
library(h2o)
library(h2o)
library(stats)
library(base)
library(randomForest)
### c5.0 tree to give the first model and result
set.seed(300)
m <- train(label ~ ., data = trl, method = "C5.0")
m
p <- predict(m, trl)
confusionMatrix(data=p, trl$label)
rp <- predict(m, tel)
confusionMatrix(data=rp, tel$label)
### c5.0 tree to give the first model and result
set.seed(300)
m <- train(label ~ ., data = trl, method = "C5.0")
m
# import the CSV file
wines<- read.csv("wines.csv")
names(wines) <- c("label",
"Alcohol",
"Malic_acid",
"Ash",
"Alcalinity_of_ash",
"Magnesium",
"Total_phenols",
"Flavanoids",
"Nonflavanoid_phenols",
"Proanthocyanins",
"Color_intensity",
"Hue",
"OD280_OD315_of_diluted_wines",
"Proline")
head(wines)
# examine the structure of the wbcd data frame
#str(wines)
library(ggplot2)
plt1 <- ggplot(wines, aes(x = Alcohol, y = Magnesium, colour = as.factor(label))) +
geom_point(size=3) +
ggtitle("Wines")
plt2 <- ggplot(wines, aes(x = Alcohol, y = Proline, colour = as.factor(label))) +
geom_point(size=3) +
ggtitle("Wines")
plt1
plt2
# table of labels
table(wines$label)
# recode label as a factor
wines$label <- factor(wines$label, levels = c("1","2","3"),
labels = c("A", "B", "C"))
# table or proportions with more informative labels
round(prop.table(table(wines$label)) * 100, digits = 1)
# create normalization function
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# normalize the wbcd data
wines_n <- as.data.frame(lapply(wines[2:14], normalize))
# add the label column
wines_n$label<-as.factor(wines[,1])
# set up trainning and test data sets
set.seed(3033)
indx <- sample(1:nrow(wines_n), as.integer(0.7*nrow(wines_n)))
#View(indx)
#indx
training <- wines_n[indx,1:13]
testing <- wines_n[-indx,1:13]
train_labels <- wines_n[indx,14]
test_labels <- wines_n[-indx,14]
trl<-wines_n[indx,]
tel<-wines_n[-indx,]
# check missing data
anyNA(training)
anyNA(testing)
# load the "class" library
library(class)
test_pred <- knn(train = training[1:13], test = testing[1:13],
cl = train_labels, k = 4)
head(testing)
head(test_pred)
# load the "gmodels" library
library(gmodels)
# Create the cross tabulation of predicted vs. actual
CrossTable(x = test_labels, y = test_pred,
prop.chisq = FALSE)
#we can see the error is not very high, only 2 mistake.
# use the scale() function to z-score standardize a data frame
wines_z <- as.data.frame(scale(wines[2:14]))
# add the label column
wines_z$label<-as.factor(wines[,1])
# set up trainning and test data sets
set.seed(3033)
indx <- sample(1:nrow(wines_z), as.integer(0.7*nrow(wines_z)))
#indx
training1 <- wines_z[indx,1:13]
testing1 <- wines_z[-indx,1:13]
train_labels1 <- wines_z[indx,14]
test_labels1 <- wines_z[-indx,14]
# check missing data
anyNA(training1)
anyNA(testing1)
#start time
strt<-Sys.time()
test_pred <- knn(train = training[1:13], test = testing[1:13], cl = train_labels, k = 1)
CrossTable(x = test_labels, y = test_pred,prop.chisq = FALSE)
test_pred <- knn(train = training[1:13], test = testing[1:13], cl = train_labels, k=4)
CrossTable(x = test_labels, y = test_pred, prop.chisq=FALSE)
test_pred <- knn(train = training[1:13], test = testing[1:13], cl = train_labels, k = 8)
CrossTable(x = test_labels, y = test_pred,prop.chisq = FALSE)
test_pred <- knn(train = training[1:13], test = testing[1:13], cl = train_labels, k=12)
CrossTable(x = test_labels, y = test_pred, prop.chisq=FALSE)
test_pred <- knn(train = training[1:13], test = testing[1:13], cl = train_labels, k = 14)
CrossTable(x = test_labels, y = test_pred,prop.chisq = FALSE)
test_pred <- knn(train = training[1:13], test = testing[1:13], cl = train_labels, k=20)
CrossTable(x = test_labels, y = test_pred, prop.chisq=FALSE)
#end time
print(Sys.time()-strt)
# we find the best is 1 mistake improve our model when k=12 and 14.
library(tidyr)
library(dplyr)
library(Rcpp)
library(ggplot2)
library(caret)
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(3333)
knn_fit <- train(label ~., data = trl, method = "knn",
trControl=trctrl,
preProcess = c("center", "scale"),
tuneLength = 10)
knn_fit
#k = 21, give the best accurarcy=0.97 and Kappa=0.95
# use the model to test the testing data
knnPredict <- predict(knn_fit,newdata = tel )
#Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(knnPredict, tel$label )
# only 3 B mistaked as A, not very high for the testing data. Also, the accurarcy is 0.9444 and the Kappa is 0.916
library(ranger)
library(randomForest)
library(caret)
library(randomForest)
set.seed(3033)
rf <- randomForest(label ~ ., data = trl)
rf
library(caret)
ctrl <- trainControl(method = "repeatedcv",
number = 10, repeats = 10)
# auto-tune a random forest
grid_rf <- expand.grid(.mtry = c(1,2,4,6))
set.seed(300)
m_rf <- train(label ~ ., data = trl, method = "rf",
metric = "Kappa", trControl = ctrl,
tuneGrid = grid_rf)
m_rf
#mtry = 1, Accurart is 0.9821404 and kappa is 0.9730934
rfPredict <- predict(m_rf,newdata = tel )
confusionMatrix(rfPredict, tel$label )
# we find that the accuray is 1 and kappa is 1, excellent.
library(broom)
library(tidyr)
library(caret)
library(tictoc)
library(lattice)
library(ggplot2)
library(ranger)
library(h2o)
library(stats)
library(base)
library(randomForest)
### c5.0 tree to give the first model and result
set.seed(300)
m <- train(label ~ ., data = trl, method = "C5.0")
m
p <- predict(m, trl)
confusionMatrix(data=p, trl$label)
rp <- predict(m, tel)
confusionMatrix(data=rp, tel$label)
trl1<-wines[indx,]
tel1<-wines[-inx,]
trl1<-wines[indx,]
tel1<-wines[-indx,]
### c5.0 tree to give the first model and result
set.seed(300)
m <- train(label ~ ., data = trl1, method = "C5.0")
m
p <- predict(m, trl1)
confusionMatrix(data=p, trl1$label)
rp <- predict(m, tel1)
confusionMatrix(data=rp, tel1$label)
